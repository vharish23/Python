{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import mode\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, plot_importance\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (294,299,300,302,307,313,315,365,367,369) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/anaconda/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (294,299,300,302,313,315,365,367,369) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Reading input files\n",
    "df = pd.read_csv(\"Documents/JK/churn_prediction/train.csv\")\n",
    "df_test = pd.read_csv(\"Documents/JK/churn_prediction/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define a generic function using Pandas replace function\n",
    "def coding(col, codeDict):\n",
    "    colCoded = pd.DataFrame(col, copy=True)\n",
    "    for key, value in codeDict.items():\n",
    "        colCoded.replace(key, value, inplace=True)\n",
    "    return colCoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change categories to numeric values\n",
    "df[[\"FINAL_WORTH_prev1\",\"ENGAGEMENT_TAG_prev1\"]] = coding(df[[\"FINAL_WORTH_prev1\",\"ENGAGEMENT_TAG_prev1\"]], {'NO':0,'LOW':1,'MEDIUM':2,'HIGH':3})\n",
    "df.rename(columns = {'FINAL_WORTH_prev1' : 'FINAL_WORTH', 'ENGAGEMENT_TAG_prev1' : 'ENGAGEMENT_TAG_LATEST'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test[[\"FINAL_WORTH_prev1\",\"ENGAGEMENT_TAG_prev1\"]] = coding(df_test[[\"FINAL_WORTH_prev1\",\"ENGAGEMENT_TAG_prev1\"]], {'NO':0,'LOW':1,'MEDIUM':2,'HIGH':3})\n",
    "df_test.rename(columns = {'FINAL_WORTH_prev1' : 'FINAL_WORTH', 'ENGAGEMENT_TAG_prev1' : 'ENGAGEMENT_TAG_LATEST'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['OCCUP_ALL_NEW'].replace(['RETIRED','NON_INDIVIDUA','MISSING'],'OTHERS',inplace=True)\n",
    "df_test['OCCUP_ALL_NEW'].replace(['RETIRED','NON_INDIVIDUA','MISSING'],'OTHERS',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 377) (200000, 376)\n"
     ]
    }
   ],
   "source": [
    "#Exploratory Data Analysis\n",
    "#Checking sample size\n",
    "print df.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Print all rows and columns. Dont hide any\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Back up for transformation - later on\n",
    "df_bkp = df\n",
    "df_test_bkp = df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['brn_code'] = df['brn_code'].apply(str)\n",
    "df_test['brn_code'] = df_test['brn_code'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove ID fields and separate Target\n",
    "df_Y = df['Responders']\n",
    "df = df.drop(['Responders','UCIC_ID'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 338) (300000, 37)\n"
     ]
    }
   ],
   "source": [
    "#Filter columns into numerical & categorical\n",
    "df_num = df.select_dtypes(include=[np.number]) #Numbers which are categories must be verified\n",
    "df_cat = df.select_dtypes(exclude=[np.number])\n",
    "print df_num.shape, df_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to check % of missing values\n",
    "def missing_values_table(df): \n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum()/len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to eliminate variables with more than 99% missing values - need function 'missing_values_table'\n",
    "def non_missing_col(df):\n",
    "    df_col = missing_values_table(df) #Calc missing values for each column\n",
    "    df_col = df_col.loc[df_col['% of Total Values'] <= 99] #Filter dataframe with less missing values\n",
    "    df_col = df_col.index.values.tolist() #Convert dataframe to columns list\n",
    "    return df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Eliminate Categorical Variables with more than 99% missing values\n",
    "df_cat_col = missing_values_table(df_cat)\n",
    "df_elim_col = df_cat_col.loc[df_cat_col['% of Total Values'] > 99]\n",
    "df_elim_col = df_elim_col.index.values.tolist()\n",
    "df_elim = df_cat[df_elim_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 16)\n"
     ]
    }
   ],
   "source": [
    "#Verify whether eliminated categorical fields have 100% correlation\n",
    "df_elim = df_elim.join(df_Y)\n",
    "print df_elim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 281) (300000, 22)\n"
     ]
    }
   ],
   "source": [
    "#Numerical variables with LT 99% missing values\n",
    "df_num_col = non_missing_col(df_num)\n",
    "df_num = df_num[df_num_col]\n",
    "#Categorical variables with LT 99% missing values\n",
    "df_cat_col = non_missing_col(df_cat)\n",
    "df_cat = df_cat[df_cat_col]\n",
    "print df_num.shape, df_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find Count of distinct values in categorical fields\n",
    "count = df_cat.apply(pd.Series.nunique)\n",
    "dstnct_cnt_col = pd.DataFrame(count, columns=['count'])\n",
    "# dstnct_cnt_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Eliminate Variables by intuition\n",
    "df_cat_col.remove('city') #Not suitable for prediction - too many values\n",
    "df_cat_col.remove('brn_code') #Not suitable for prediction - too many values\n",
    "df_cat = df_cat[df_cat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Find Count of distinct values in categorical fields\n",
    "count = df_cat.apply(pd.Series.nunique)\n",
    "dstnct_cnt_col = pd.DataFrame(count, columns=['count'])\n",
    "# dstnct_cnt_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Binary Variables(1 or 2)\n",
    "df_binary_col = dstnct_cnt_col.loc[dstnct_cnt_col['count'] <=2]\n",
    "df_binary_col = df_binary_col.index.values.tolist()\n",
    "df_binary = df_cat[df_binary_col]\n",
    "#Nominal Variables(2+)\n",
    "df_nominal_col = dstnct_cnt_col.loc[dstnct_cnt_col['count'] >2]\n",
    "df_nominal_col = df_nominal_col.index.values.tolist()\n",
    "df_nominal = df_cat[df_nominal_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_bkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Eliminate Variables by intuition\n",
    "df_num_col.remove('zip') #Not suitable for prediction - too many values\n",
    "df_num = df_num[df_num_col]\n",
    "df_binary_col.remove('FRX_PrevQ1_N') #Not suitable for prediction - single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = df_test_bkp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cust_id_test = df_test[['UCIC_ID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 377) (200000, 376)\n"
     ]
    }
   ],
   "source": [
    "print df.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (240000, 377)\n",
      "Validation shape :  (60000, 377)\n"
     ]
    }
   ],
   "source": [
    "#Training_Validation Split\n",
    "df_train, df_validation = train_test_split(df,test_size=0.20,random_state=190)\n",
    "print \"Train shape : \",df_train.shape\n",
    "print \"Validation shape : \",df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000,) (60000,)\n"
     ]
    }
   ],
   "source": [
    "#training Target\n",
    "train_Y = df_train ['Responders']\n",
    "validation_Y = df_validation ['Responders']\n",
    "print train_Y.shape, validation_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (240000, 376)\n",
      "Validation shape :  (60000, 376)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.drop(['Responders'], axis =1)\n",
    "df_validation = df_validation.drop(['Responders'], axis =1)\n",
    "print \"Train shape : \",df_train.shape\n",
    "print \"Validation shape : \",df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_num = df_train[df_num_col]\n",
    "df_validation_num = df_validation[df_num_col]\n",
    "df_test_num = df_test[df_num_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 280) (60000, 280) (200000, 280)\n"
     ]
    }
   ],
   "source": [
    "print df_train_num.shape, df_validation_num.shape, df_test_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Impute median values for numerical variables\n",
    "def impute_median(df):\n",
    "    fill_NaN = Imputer(missing_values=np.nan, strategy='median', axis=1)\n",
    "    imputed_df = pd.DataFrame(fill_NaN.fit_transform(df))\n",
    "    imputed_df.columns = df.columns\n",
    "    imputed_df.index = df.index\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputed_df_train_num = impute_median(df_train_num)\n",
    "imputed_df_validation_num = impute_median(df_validation_num)\n",
    "imputed_df_test_num = impute_median(df_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 280) (60000, 280) (200000, 280)\n"
     ]
    }
   ],
   "source": [
    "print imputed_df_train_num.shape, imputed_df_validation_num.shape, imputed_df_test_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HNW_CATEGORY',\n",
       " 'OCCUP_ALL_NEW',\n",
       " 'Charges_cnt_PrevQ1_N',\n",
       " 'RBI_Class_Audit',\n",
       " 'gender_bin']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nominal_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Handling Categorical variables\n",
    "df_train_nominal = df_train[df_nominal_col]\n",
    "df_validation_nominal = df_validation[df_nominal_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_test_cat = df_test[df_cat_col]\n",
    "df_test_nominal = df_test[df_nominal_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print df_test_cat.shape, df_test_nominal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def impute_mode(df):\n",
    "    imputed_df = df.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "    return imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imputed_df_train_nominal = impute_mode(df_train_nominal)\n",
    "imputed_df_validation_nominal = impute_mode(df_validation_nominal)\n",
    "imputed_df_test_nominal = impute_mode(df_test_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Function to creating dummy variables for Nominal fields for a set of columns\n",
    "def create_dummy_set(df_col,df):\n",
    "    for i in df_col:\n",
    "        dummies = pd.get_dummies(df[i]).rename(columns=lambda x: i+'_'+ str(x))\n",
    "        #Adding to input variables\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "        #Dropping column without having to reassign\n",
    "        df.drop([i], inplace=True, axis=1)\n",
    "        print df.shape\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 7)\n",
      "(240000, 12)\n",
      "(240000, 15)\n",
      "(240000, 18)\n",
      "(240000, 20)\n",
      "(60000, 7)\n",
      "(60000, 12)\n",
      "(60000, 15)\n",
      "(60000, 18)\n",
      "(60000, 20)\n",
      "(200000, 7)\n",
      "(200000, 12)\n",
      "(200000, 15)\n",
      "(200000, 18)\n",
      "(200000, 20)\n"
     ]
    }
   ],
   "source": [
    "df_train_nominal = create_dummy_set(df_nominal_col,imputed_df_train_nominal)\n",
    "df_validation_nominal = create_dummy_set(df_nominal_col,imputed_df_validation_nominal)\n",
    "df_test_nominal = create_dummy_set(df_nominal_col,imputed_df_test_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_binary = df_train[df_binary_col]\n",
    "df_validation_binary = df_validation[df_binary_col]\n",
    "df_test_binary = df_test[df_binary_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 14)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 15)\n",
      "(240000, 16)\n",
      "(240000, 17)\n",
      "(60000, 14)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 15)\n",
      "(60000, 16)\n",
      "(60000, 17)\n"
     ]
    }
   ],
   "source": [
    "df_train_binary = create_dummy_set(df_binary_col,df_train_binary)\n",
    "df_validation_binary = create_dummy_set(df_binary_col,df_validation_binary)\n",
    "df_train_binary = df_train_binary[df_train_binary.columns.drop(list(df_train_binary.filter(regex='MISSING')))]\n",
    "df_validation_binary = df_validation_binary[df_validation_binary.columns.drop(list(df_validation_binary.filter(regex='MISSING')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 14)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 15)\n",
      "(200000, 16)\n",
      "(200000, 17)\n"
     ]
    }
   ],
   "source": [
    "df_test_binary = create_dummy_set(df_binary_col,df_test_binary)\n",
    "df_test_binary = df_test_binary[df_test_binary.columns.drop(list(df_test_binary.filter(regex='MISSING')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMAIL_UNSUBSCRIBE_Y</th>\n",
       "      <th>EFT_SELF_TRANSFER_PrevQ1_N</th>\n",
       "      <th>EFT_SELF_TRANSFER_PrevQ1_Y</th>\n",
       "      <th>AL_TAG_LIVE_Y</th>\n",
       "      <th>CC_TAG_LIVE_Y</th>\n",
       "      <th>DEMAT_TAG_LIVE_Y</th>\n",
       "      <th>HL_TAG_LIVE_Y</th>\n",
       "      <th>SEC_ACC_TAG_LIVE_Y</th>\n",
       "      <th>INS_TAG_LIVE_Y</th>\n",
       "      <th>MF_TAG_LIVE_Y</th>\n",
       "      <th>OTHER_LOANS_TAG_LIVE_Y</th>\n",
       "      <th>RD_TAG_LIVE_Y</th>\n",
       "      <th>FD_TAG_LIVE_Y</th>\n",
       "      <th>Billpay_Active_PrevQ1_N_B_1</th>\n",
       "      <th>Billpay_Reg_ason_Prev1_N_B_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EMAIL_UNSUBSCRIBE_Y  EFT_SELF_TRANSFER_PrevQ1_N  \\\n",
       "0                    0                           1   \n",
       "1                    0                           1   \n",
       "2                    0                           1   \n",
       "3                    0                           1   \n",
       "4                    0                           1   \n",
       "\n",
       "   EFT_SELF_TRANSFER_PrevQ1_Y  AL_TAG_LIVE_Y  CC_TAG_LIVE_Y  DEMAT_TAG_LIVE_Y  \\\n",
       "0                           0              0              1                 0   \n",
       "1                           0              0              0                 0   \n",
       "2                           0              0              1                 0   \n",
       "3                           0              0              0                 0   \n",
       "4                           0              0              1                 0   \n",
       "\n",
       "   HL_TAG_LIVE_Y  SEC_ACC_TAG_LIVE_Y  INS_TAG_LIVE_Y  MF_TAG_LIVE_Y  \\\n",
       "0              0                   0               0              0   \n",
       "1              0                   0               0              0   \n",
       "2              0                   0               0              0   \n",
       "3              0                   0               0              0   \n",
       "4              0                   0               0              0   \n",
       "\n",
       "   OTHER_LOANS_TAG_LIVE_Y  RD_TAG_LIVE_Y  FD_TAG_LIVE_Y  \\\n",
       "0                       0              1              0   \n",
       "1                       0              0              1   \n",
       "2                       1              0              0   \n",
       "3                       0              0              0   \n",
       "4                       1              0              0   \n",
       "\n",
       "   Billpay_Active_PrevQ1_N_B_1  Billpay_Reg_ason_Prev1_N_B_1  \n",
       "0                            0                             1  \n",
       "1                            0                             0  \n",
       "2                            0                             0  \n",
       "3                            0                             1  \n",
       "4                            1                             1  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_binary.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_binary.drop('EFT_SELF_TRANSFER_PrevQ1_N', axis=1, inplace=True)\n",
    "df_validation_binary.drop('EFT_SELF_TRANSFER_PrevQ1_N', axis=1, inplace=True)\n",
    "df_test_binary.drop('EFT_SELF_TRANSFER_PrevQ1_N', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 314)\n"
     ]
    }
   ],
   "source": [
    "df_train = imputed_df_train_num.join(df_train_nominal).join(df_train_binary)\n",
    "print df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 314)\n"
     ]
    }
   ],
   "source": [
    "df_validation = imputed_df_validation_num.join(df_validation_nominal).join(df_validation_binary)\n",
    "print df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 314)\n"
     ]
    }
   ],
   "source": [
    "df_test = imputed_df_test_num.join(df_test_nominal).join(df_test_binary)\n",
    "print df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 314) (60000, 314) (200000, 314)\n"
     ]
    }
   ],
   "source": [
    "print df_train.shape, df_validation.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_xgb = xgb.XGBClassifier(objective='binary:logistic',max_depth=5,n_estimators=1000,colsample_bytree=.75,learning_rate=0.06).fit(df_train, train_Y,eval_metric='auc')\n",
    "train_pred = _xgb.predict_proba(df_train)\n",
    "val_pred = _xgb.predict_proba(df_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.56566976384\n",
      "0.492815121998\n",
      "[[193775   4897]\n",
      " [ 17950  23378]]\n",
      "[[47856  1775]\n",
      " [ 5259  5110]]\n"
     ]
    }
   ],
   "source": [
    "train_pred_val = _xgb.predict(df_train)\n",
    "val_pred_val = _xgb.predict(df_validation)\n",
    "print recall_score(train_Y, train_pred_val)\n",
    "print recall_score(validation_Y, val_pred_val)\n",
    "print confusion_matrix(train_Y, train_pred_val)\n",
    "print confusion_matrix(validation_Y, val_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pred = _xgb.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_pred = pd.DataFrame(test_pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_result = Cust_id_test.join(df_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_result = predicted_result.rename(columns = {0 : 'Non-Responders', 1 : 'Responders'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_result = predicted_result.drop('Non-Responders', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UCIC_ID</th>\n",
       "      <th>Responders</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337734</td>\n",
       "      <td>0.306379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>488166</td>\n",
       "      <td>0.027382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410785</td>\n",
       "      <td>0.071905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>389145</td>\n",
       "      <td>0.098597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221090</td>\n",
       "      <td>0.164572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2651</td>\n",
       "      <td>0.013117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>344310</td>\n",
       "      <td>0.045364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>53881</td>\n",
       "      <td>0.024969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>499665</td>\n",
       "      <td>0.065219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>482927</td>\n",
       "      <td>0.042110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UCIC_ID  Responders\n",
       "0   337734    0.306379\n",
       "1   488166    0.027382\n",
       "2   410785    0.071905\n",
       "3   389145    0.098597\n",
       "4   221090    0.164572\n",
       "5     2651    0.013117\n",
       "6   344310    0.045364\n",
       "7    53881    0.024969\n",
       "8   499665    0.065219\n",
       "9   482927    0.042110"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_result.to_csv(\"Documents/JK/churn_prediction/BOG_SB_output.csv\",sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
